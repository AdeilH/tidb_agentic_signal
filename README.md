# TiDB-Powered Crypto Signals Bot

A sophisticated, multi-tenant cryptocurrency trading signals bot that maximizes TiDB's advanced features including vector storage, TTL (Time-To-Live), and distributed architecture.

## ğŸš€ TiDB Features Showcased

### 1. **TTL (## ğŸ§ª Testing

### Unit Tests
```bash
# Run all unit tests
go test ./... -v

# Run tests for specific package
go test ./internal/db -v
go test ./internal/predictor -v
```

### Integration Tests
Comprehensive integration tests validate the complete system with real TiDB, Kimi AI, and Binance APIs.

```bash
# Run all integration tests
./test/integration/run_tests.sh

# Run specific test suites
./test/integration/run_tests.sh tidb      # TiDB features only
./test/integration/run_tests.sh ai        # Kimi AI integration
./test/integration/run_tests.sh binance   # Binance API testing
./test/integration/run_tests.sh e2e       # End-to-end signal generation
./test/integration/run_tests.sh api       # HTTP API testing
./test/integration/run_tests.sh bench     # Performance benchmarks
```

#### What Gets Tested
- âœ… **TiDB Features**: TTL, vector storage, multi-tenant isolation
- âœ… **AI Integration**: Real Kimi AI prediction generation
- âœ… **External APIs**: Binance testnet connectivity and data
- âœ… **End-to-End Flow**: Complete signal generation pipeline
- âœ… **Performance**: Database operation benchmarks
- âœ… **API Endpoints**: REST API and WebSocket functionality

For detailed testing documentation, see [INTEGRATION_TESTING.md](INTEGRATION_TESTING.md).

## ğŸ”§ Development

### Prerequisites
- Go 1.25+
- Docker & Docker Compose
- Valid API keys (Kimi AI, Binance TestNet)

### Quick Development Setup
```bash
# 1. Clone and setup
git clone <repository-url>
cd agentic_go_signals
cp .env.example .env
# Edit .env with your API keys

# 2. Start TiDB cluster
docker-compose up -d

# 3. Run tests to validate setup
./test/integration/run_tests.sh

# 4. Start development server
go run cmd/all/main.go
```

### Code Quality
```bash
# Format code
go fmt ./...

# Vet code
go vet ./...

# Run linter (if golangci-lint installed)
golangci-lint run
```

## ğŸ” Security Featuresime-To-Live) Data Management**
- **Automatic Data Expiration**: Events and event vectors automatically expire after 30 days
- **Storage Optimization**: Prevents database bloat with automatic cleanup
- **Implementation**: Raw SQL with `TTL = 30 DAY` on `event_vecs` table

```sql
CREATE TABLE event_vecs (
    -- columns...
) TTL = ts + INTERVAL 30 DAY;
```

### 2. **Vector Storage with JSON**
- **High-Dimensional Data**: Store 128-dimensional vectors for semantic search
- **Flexible Schema**: JSON column allows varying vector dimensions
- **Implementation**: Custom vector generation and storage pipeline

### 3. **Multi-Tenant Architecture**
- **Composite Primary Keys**: `(bot_id, id)` ensures tenant isolation
- **Horizontal Scaling**: Each bot operates independently
- **Data Separation**: Clean separation between different trading bots

### 4. **Distributed Database Support**
- **TiKV Integration**: Leverages TiDB's distributed storage layer
- **PD Cluster**: Placement Driver for metadata management
- **Docker Compose**: Local TiDB cluster with PD, TiKV, and TiDB components

### 5. **Real-Time WebSocket Updates**
- **Live Data Streaming**: Real-time updates via WebSocket connections
- **Event Broadcasting**: Ingestion, prediction, and trade events
- **Scalable Architecture**: Hub pattern for managing multiple connections

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   TiDB Cluster   â”‚    â”‚   API Gateway   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ CryptoCompare â”‚â”€â”€â”€â–¶â”‚ â€¢ TTL Tables     â”‚â—€â”€â”€â”€â”‚ â€¢ Fiber v2 API  â”‚
â”‚ â€¢ Blockchain.io â”‚    â”‚ â€¢ Vector Storage â”‚    â”‚ â€¢ WebSocket Hub â”‚
â”‚ â€¢ Market Data   â”‚    â”‚ â€¢ Multi-Tenant   â”‚    â”‚ â€¢ Real-time     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ingest Pipeline â”‚    â”‚ Predictor AI     â”‚    â”‚ Risk Manager    â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ News Fetcher  â”‚    â”‚ â€¢ Kimi AI        â”‚    â”‚ â€¢ Position Size â”‚
â”‚ â€¢ Chain Metrics â”‚    â”‚ â€¢ Context Build  â”‚    â”‚ â€¢ Stop Loss     â”‚
â”‚ â€¢ Vector Gen    â”‚    â”‚ â€¢ DB Persistence â”‚    â”‚ â€¢ Risk Limits   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Trading Engine   â”‚
                    â”‚                  â”‚
                    â”‚ â€¢ Binance TestNetâ”‚
                    â”‚ â€¢ Paper Trading  â”‚
                    â”‚ â€¢ Orchestrator   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Project Structure

```
agentic_go_signals/
â”œâ”€â”€ cmd/all/                    # Main application entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/                    # Fiber v2 REST API + WebSocket
â”‚   â”œâ”€â”€ chain/                  # Blockchain metrics (blockchain.info)
â”‚   â”œâ”€â”€ config/                 # Environment configuration
â”‚   â”œâ”€â”€ db/                     # TiDB models and migrations
â”‚   â”œâ”€â”€ ingest/                 # Data ingestion pipeline
â”‚   â”œâ”€â”€ kimi/                   # Kimi AI client (Moonshot)
â”‚   â”œâ”€â”€ news/                   # News fetcher (CryptoCompare)
â”‚   â”œâ”€â”€ notifications/          # Slack notifications (configurable)
â”‚   â”œâ”€â”€ predictor/              # AI prediction service
â”‚   â”œâ”€â”€ risk/                   # Risk management calculator
â”‚   â”œâ”€â”€ svc/                    # Service initialization
â”‚   â”œâ”€â”€ trader/                 # Binance TestNet integration
â”‚   â””â”€â”€ worker/                 # Orchestrator for pipeline
â”œâ”€â”€ docker-compose.yml          # TiDB cluster setup
â”œâ”€â”€ .env.example               # Environment variables template
â””â”€â”€ README.md                  # This file
```

## ğŸ› ï¸ Installation & Setup

### 1. Clone Repository
```bash
git clone <repository-url>
cd agentic_go_signals
```

### 2. Start TiDB Cluster
```bash
docker-compose up -d
```

This starts:
- **TiDB Server** (port 4000): SQL interface
- **PD Server** (port 2379): Placement Driver
- **TiKV Server** (port 20160): Distributed storage

### 3. Configure Environment
```bash
cp .env.example .env
# Edit .env with your API keys:
# - KIMI_API_KEY=your_moonshot_api_key
# - BINANCE_TEST_KEY=your_testnet_key
# - BINANCE_TEST_SECRET=your_testnet_secret
# - SLACK_WEBHOOK_URL=optional_slack_webhook (leave empty to disable)
```

### 4. Build & Run
```bash
go build -o bin/sigforge ./cmd/all
./bin/sigforge
```

## ğŸ§ª Testing

Run all tests across the project:
```bash
go test ./... -v
```

Individual package tests:
```bash
go test ./internal/db/ -v      # Database models
go test ./internal/api/ -v     # API endpoints
go test ./internal/risk/ -v    # Risk calculations
go test ./internal/worker/ -v  # Orchestrator
```

## ğŸ”— API Endpoints

### Core Endpoints
- `GET /healthz` - Health check
- `POST /bot/create` - Create new trading bot
- `GET /bot/:id` - Get bot details
- `GET /bot/:id/signals` - Get trading signals

### Data Endpoints
- `POST /ingest/manual` - Manual data ingestion
- `GET /predictions/:bot_id/:symbol` - Get predictions
- `GET /trades/:bot_id` - Get trade history

### WebSocket
- `WS /ws` - Real-time updates stream

## ğŸ“Š TiDB Schema Design

### Events Table (TTL Enabled)
```sql
CREATE TABLE events (
    id BIGINT AUTO_INCREMENT,
    bot_id VARCHAR(50),
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    symbol VARCHAR(20),
    source VARCHAR(50),
    usd_val DECIMAL(20,8),
    text TEXT,
    PRIMARY KEY (bot_id, id)
);

CREATE TABLE event_vecs (
    id BIGINT AUTO_INCREMENT,
    bot_id VARCHAR(50),
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    sym VARCHAR(20),
    vec JSON,
    text TEXT,
    PRIMARY KEY (bot_id, id)
) TTL = ts + INTERVAL 30 DAY;
```

### Multi-Tenant Design
- **Composite Keys**: `(bot_id, id)` ensures data isolation
- **Partitioning**: Each bot's data is logically separated
- **Scalability**: Add new bots without schema changes

## ğŸ¤– AI Integration

### Kimi AI (Moonshot)
- **Context Building**: Combines news and chain metrics
- **Prediction Generation**: AI-driven market analysis
- **Confidence Scoring**: Quantified prediction confidence

### Vector Search (Future)
- **Semantic Similarity**: Find similar market conditions
- **Pattern Recognition**: Historical pattern matching
- **Contextual Retrieval**: Enhanced AI context

## âš–ï¸ Risk Management

### Position Sizing
- **Account Balance Based**: Percentage of total capital
- **Risk Per Trade**: Configurable risk tolerance (e.g., 2%)
- **Stop Loss Calculation**: Automatic stop loss prices

### Risk Limits
- **Maximum Position Size**: Per-trade position limits
- **Total Exposure**: Portfolio-wide exposure limits
- **Validation**: Pre-trade risk checks

## ğŸ”„ Pipeline Orchestration

### Worker Coordination
1. **Ingestion Worker**: Fetches news and chain metrics (5min interval)
2. **Prediction Worker**: Generates AI predictions (10min interval)
3. **Execution Worker**: Evaluates and executes trades (1min interval)

### Data Flow
```
News/Chain Data â†’ Ingestion â†’ Vector Storage â†’ AI Analysis â†’ Risk Check â†’ Trade Execution
```

## ğŸš€ Deployment Considerations

### Scaling TiDB
- **Horizontal Scaling**: Add TiKV nodes for storage
- **Read Replicas**: TiDB nodes for read scaling
- **Regional Deployment**: Multi-region setup for latency

### Application Scaling
- **Stateless Design**: Easy horizontal scaling
- **Bot Isolation**: Independent bot operations
- **WebSocket Clustering**: Load balancer with sticky sessions

## ğŸ“ˆ Performance Features

### TiDB Optimizations
- **Clustered Index**: Primary key clustering for performance
- **TTL Automation**: Automatic cleanup reduces maintenance
- **JSON Indexing**: Efficient vector column operations

### Application Optimizations
- **Connection Pooling**: Efficient database connections
- **Async Processing**: Non-blocking pipeline operations
- **Concurrent Workers**: Parallel processing capabilities

## ï¿½ Configurable Notifications

### Slack Integration
- **Optional Configuration**: Set `SLACK_WEBHOOK_URL` environment variable to enable
- **Smart Fallback**: Gracefully skips notifications when not configured
- **Rich Messages**: Trading signals, predictions, and error alerts
- **Formatted Updates**: Color-coded messages with timestamps

### Notification Types
- **Trade Execution**: Real-time trading signal notifications
- **AI Predictions**: Market prediction alerts with confidence scores
- **System Errors**: Error alerts for debugging and monitoring
- **Custom Messages**: Flexible message structure for future extensions

## ï¿½ğŸ” Security Features

### Data Protection
- **Environment Variables**: Secure API key management
- **TestNet Only**: Safe paper trading environment
- **Input Validation**: SQL injection prevention

### Multi-Tenancy Security
- **Bot Isolation**: Complete data separation
- **Access Control**: Bot-specific data access
- **Audit Trail**: Complete trade history tracking

## ğŸ¯ Next Steps

1. **Enhanced Vector Search**: Implement semantic similarity queries
2. **Real Market Data**: Integrate live price feeds
3. **Advanced AI Models**: Multi-model ensemble predictions
4. **Performance Monitoring**: TiDB cluster monitoring
5. **Production Deployment**: Kubernetes orchestration

---

## ğŸ“„ License

This project is part of a TiDB hackathon submission showcasing advanced database features in a real-world application.

## ğŸ¤ Contributing

This is a hackathon project. For production use, consider:
- Enhanced error handling
- Comprehensive logging
- Production-grade security
- Performance optimization
- Monitoring and alerting
